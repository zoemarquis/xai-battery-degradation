{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN : LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import pickle \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# reproductibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ICI ON RÈGLE QUELLE TAILLE DE FENETRE ON VEUT UTILISER (POUR NE PAS DUPLIQUER LE CODE)\n",
    "taille_fenetre_to_run = \"courte\"\n",
    "assert taille_fenetre_to_run in [\"courte\", \"moyenne\", \"longue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if taille_fenetre_to_run == \"courte\":\n",
    "    run_split = pickle.load(open(\"Data/splits_courte.pkl\", \"rb\"))\n",
    "elif taille_fenetre_to_run == \"moyenne\":\n",
    "    run_split = pickle.load(open(\"Data/splits_moyenne.pkl\", \"rb\"))\n",
    "else:\n",
    "    run_split = pickle.load(open(\"Data/splits_longue.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(run_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X_train_np_label', 'X_train_np_binary', 'y_train_np', 'X_train_df_label', 'X_train_df_binary', 'y_train_df', 'X_test_np_label', 'X_test_np_binary', 'y_test_np', 'X_test_df_label', 'X_test_df_binary', 'y_test_df'])\n",
      "dict_keys(['X_train_np_label', 'X_train_np_binary', 'y_train_np', 'X_train_df_label', 'X_train_df_binary', 'y_train_df', 'X_test_np_label', 'X_test_np_binary', 'y_test_np', 'X_test_df_label', 'X_test_df_binary', 'y_test_df'])\n",
      "dict_keys(['X_train_np_label', 'X_train_np_binary', 'y_train_np', 'X_train_df_label', 'X_train_df_binary', 'y_train_df', 'X_test_np_label', 'X_test_np_binary', 'y_test_np', 'X_test_df_label', 'X_test_df_binary', 'y_test_df'])\n",
      "dict_keys(['X_train_np_label', 'X_train_np_binary', 'y_train_np', 'X_train_df_label', 'X_train_df_binary', 'y_train_df', 'X_test_np_label', 'X_test_np_binary', 'y_test_np', 'X_test_df_label', 'X_test_df_binary', 'y_test_df'])\n",
      "dict_keys(['X_train_np_label', 'X_train_np_binary', 'y_train_np', 'X_train_df_label', 'X_train_df_binary', 'y_train_df', 'X_test_np_label', 'X_test_np_binary', 'y_test_np', 'X_test_df_label', 'X_test_df_binary', 'y_test_df'])\n"
     ]
    }
   ],
   "source": [
    "# utiser binary encoding dans RNN \n",
    "\n",
    "split_0 = run_split[0]\n",
    "split_1 = run_split[1]\n",
    "split_2 = run_split[2]\n",
    "split_3 = run_split[3]\n",
    "split_4 = run_split[4]\n",
    "\n",
    "# Vérifier qu'ils ont tous les mêmes clefs\n",
    "print(split_0.keys())\n",
    "print(split_1.keys())\n",
    "print(split_2.keys())\n",
    "print(split_3.keys())\n",
    "print(split_4.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X_train_np_binary', 'y_train_np', 'X_train_df_binary', 'y_train_df', 'X_test_np_binary', 'y_test_np', 'X_test_df_binary', 'y_test_df'])\n",
      "dict_keys(['X_train_np_binary', 'y_train_np', 'X_train_df_binary', 'y_train_df', 'X_test_np_binary', 'y_test_np', 'X_test_df_binary', 'y_test_df'])\n",
      "dict_keys(['X_train_np_binary', 'y_train_np', 'X_train_df_binary', 'y_train_df', 'X_test_np_binary', 'y_test_np', 'X_test_df_binary', 'y_test_df'])\n",
      "dict_keys(['X_train_np_binary', 'y_train_np', 'X_train_df_binary', 'y_train_df', 'X_test_np_binary', 'y_test_np', 'X_test_df_binary', 'y_test_df'])\n",
      "dict_keys(['X_train_np_binary', 'y_train_np', 'X_train_df_binary', 'y_train_df', 'X_test_np_binary', 'y_test_np', 'X_test_df_binary', 'y_test_df'])\n"
     ]
    }
   ],
   "source": [
    "# Drop window_tipe, X_train_label, X_test_label, X_train_df_label, X_test_df_label\n",
    "for s in [split_0, split_1, split_2, split_3, split_4]:\n",
    "    s.pop('X_train_np_label')\n",
    "    s.pop('X_test_np_label')\n",
    "    s.pop('X_train_df_label')\n",
    "    s.pop('X_test_df_label')\n",
    "    print(s.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vérification pour split_0:\n",
      "Vérification pour split_1:\n",
      "Vérification pour split_2:\n",
      "Vérification pour split_3:\n",
      "Vérification pour split_4:\n"
     ]
    }
   ],
   "source": [
    "# Vérifier que pour toutes les colonnes, chaque valeur min et max est 0 et 1\n",
    "\n",
    "# Vérifier pour chaque split\n",
    "for i, split in enumerate(run_split):\n",
    "    print(f\"Vérification pour split_{i}:\")\n",
    "    X_train_binary, X_test_binary = split['X_train_np_binary'], split['X_test_np_binary']\n",
    "\n",
    "    min_train = np.min(X_train_binary, axis=(0,1))  # Min pour chaque feature\n",
    "    max_train = np.max(X_train_binary, axis=(0,1))  # Max pour chaque feature\n",
    "    min_test = np.min(X_test_binary, axis=(0,1))  # Min pour chaque feature\n",
    "    max_test = np.max(X_test_binary, axis=(0,1))  # Max pour chaque feature\n",
    "\n",
    "    # print(f\"Min train: {min_train}\")\n",
    "    # print(f\"Max train: {max_train}\")\n",
    "    # print(f\"Min test: {min_test}\")\n",
    "    # print(f\"Max test: {max_test}\")\n",
    "\n",
    "    assert np.all(min_train >= 0), \"Min train < 0\"\n",
    "    assert np.all(min_train <= 1), \"Min train > 1\"\n",
    "    assert np.all(max_train >= 0), \"Max train < 0\"\n",
    "    assert np.all(max_train <= 1), \"Max train > 1\"\n",
    "    assert np.all(min_test >= 0), \"Min test < 0\"\n",
    "    assert np.all(min_test <= 1), \"Min test > 1\"\n",
    "    assert np.all(max_test >= 0), \"Max test < 0\"\n",
    "    assert np.all(max_test <= 1), \"Max test > 1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm(input_shape, units=100, dropout_rate=0.2, activation = 'tanh', learning_rate = 0.001):\n",
    "\n",
    "    # pour ajouter des couches \n",
    "    model = Sequential()\n",
    "\n",
    "    # units : 100, Plus ce nombre est élevé, plus le modèle peut capturer de relations complexes dans les données, mais cela augmente aussi le coût computationnel.\n",
    "    # activation : tanh, fonction d'activation tanh (classique dans les LSTM)\n",
    "    model.add(LSTM(units, input_shape=input_shape, activation=activation))\n",
    "\n",
    "    # éviter surapprentissage\n",
    "    model.add(Dropout(dropout_rate)) \n",
    "\n",
    "    # output pour un problème de régresssion \n",
    "    model.add(Dense(1)) \n",
    "\n",
    "    # optimizer adam \n",
    "    # mse : typique pour un problème de régression\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse') # mse pour un problème de régression ?\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_0\n",
      "Input shape: (50, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoemarquis/Documents/projet_industrie/projet_batteries/mon_venv/lib/python3.11/site-packages/sklearn/utils/_tags.py:354: FutureWarning: The KerasRegressor or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# model = create_lstm(input_shape)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m gridsearch \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# attention j'ai déjà de la validation croisée moi, donc pas de cv ici  \u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mgridsearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# callbacks=[early_stopping], verbose=1)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, callbacks=[early_stopping], verbose=1)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# model_filename = f\"Data/lstm_model_{taille_fenetre_to_run}_split_{i}.h5\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# score = model.evaluate(X_test, y_test, verbose=0)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# scores.append(score)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgridsearch\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/projet_industrie/projet_batteries/mon_venv/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projet_industrie/projet_batteries/mon_venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:932\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    928\u001b[0m params \u001b[38;5;241m=\u001b[39m _check_method_params(X, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m    930\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_routed_params_for_fit(params)\n\u001b[0;32m--> 932\u001b[0m cv_orig \u001b[38;5;241m=\u001b[39m check_cv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv, y, classifier\u001b[38;5;241m=\u001b[39m\u001b[43mis_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    933\u001b[0m n_splits \u001b[38;5;241m=\u001b[39m cv_orig\u001b[38;5;241m.\u001b[39mget_n_splits(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)\n\u001b[1;32m    935\u001b[0m base_estimator \u001b[38;5;241m=\u001b[39m clone(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)\n",
      "File \u001b[0;32m~/Documents/projet_industrie/projet_batteries/mon_venv/lib/python3.11/site-packages/sklearn/base.py:1237\u001b[0m, in \u001b[0;36mis_classifier\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m   1230\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing a class to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mprint\u001b[39m(inspect\u001b[38;5;241m.\u001b[39mstack()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1232\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in 1.8. Use an instance of the class instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1233\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1234\u001b[0m     )\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_estimator_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/projet_industrie/projet_batteries/mon_venv/lib/python3.11/site-packages/sklearn/utils/_tags.py:405\u001b[0m, in \u001b[0;36mget_tags\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[0;32m--> 405\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[0;32m~/Documents/projet_industrie/projet_batteries/mon_venv/lib/python3.11/site-packages/sklearn/base.py:613\u001b[0m, in \u001b[0;36mRegressorMixin.__sklearn_tags__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 613\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m()\n\u001b[1;32m    614\u001b[0m     tags\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregressor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    615\u001b[0m     tags\u001b[38;5;241m.\u001b[39mregressor_tags \u001b[38;5;241m=\u001b[39m RegressorTags()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "param_grid = {\n",
    "    'model__units': [50, 100, 200],\n",
    "    'dropout_rate': [0.2, 0.3, 0.5],\n",
    "    'model__activation': ['tanh', 'relu'],\n",
    "    'learning_rate': [0.001, 0.01, 0.1], \n",
    "    'batch_size': [32, 64, 128], \n",
    "    'epochs': [100, 200, 300]\n",
    "}\n",
    "\n",
    "for i, split in enumerate(run_split):\n",
    "    print(f\"Split_{i}\")\n",
    "\n",
    "    X_train, y_train = split['X_train_np_binary'], split['y_train_np']\n",
    "    X_test, y_test = split['X_test_np_binary'], split['y_test_np']\n",
    "\n",
    "    input_shape = X_train.shape[1:]\n",
    "    print(f'Input shape: {input_shape}')\n",
    "\n",
    "    model = KerasRegressor(build_fn=create_lstm, input_shape=input_shape, verbose=1) # , units=100, dropout_rate=0.2, activation='tanh', learning_rate=0.001, epochs=100, batch_size=32, verbose=1)\n",
    "    # model = create_lstm(input_shape)\n",
    "\n",
    "    gridsearch = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1) # attention j'ai déjà de la validation croisée moi, donc pas de cv ici  \n",
    "\n",
    "    gridsearch.fit(X_train, y_train, validation_data=(X_test, y_test), verbose=1) # callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    # model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    # model_filename = f\"Data/lstm_model_{taille_fenetre_to_run}_split_{i}.h5\"\n",
    "    # model.save(model_filename)\n",
    "\n",
    "    # score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    # scores.append(score)\n",
    "\n",
    "    print(f\"Best params: {gridsearch.best_params_}\")\n",
    "    print(f\"Best score: {gridsearch.best_score_}\")\n",
    "\n",
    "    best_model = gridsearch.best_estimator_\n",
    "    best_model_filename = f\"Data/lstm_model_{taille_fenetre_to_run}_split_{i}.h5\"\n",
    "    best_model.model.save(best_model_filename)\n",
    "\n",
    "    score = best_model.score(X_test, y_test)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Performance de chaque split: {scores}\")\n",
    "print(f\"Performance moyenne: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# random forest : label encoding\n",
    "# régresssion linéaire : binary encoding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mon_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
